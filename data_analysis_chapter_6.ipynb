{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Loading, Storage, and File Formats</h1>\n",
    "<p>The 6th chapter of the Python for Data Analysis, 3E</p>\n",
    "<br>\n",
    "<h3>Reading and Writing Data in Text Format</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,b,c,d,message\n",
      "1,2,3,4,hello\n",
      "5,6,7,8,world\n",
      "9,10,11,12,foo\n",
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "1,2,3,4,hello\n",
      "5,6,7,8,world\n",
      "9,10,11,12,foo\n",
      "         a   b   c   d\n",
      "message               \n",
      "hello    1   2   3   4\n",
      "world    5   6   7   8\n",
      "foo      9  10  11  12\n",
      "            A         B         C\n",
      "aaa -0.264438 -1.026059 -0.619500\n",
      "bbb  0.927272  0.302904 -0.032399\n",
      "ccc -0.264273 -0.386314 -0.217601\n",
      "ddd -0.871858 -0.348382  1.100491\n",
      "\n",
      "            A         B         C\n",
      "aaa -0.264438 -1.026059 -0.619500\n",
      "bbb  0.927272  0.302904 -0.032399\n",
      "ccc -0.264273 -0.386314 -0.217601\n",
      "ddd -0.871858 -0.348382  1.100491\n",
      "# hey!\n",
      "a,b,c,d,message\n",
      "# just wanted to make things more difficult for you\n",
      "# who reads CSV files with computers, anyway?\n",
      "1,2,3,4,hello\n",
      "5,6,7,8,world\n",
      "9,10,11,12,foo\n",
      "         a   b   c   d\n",
      "message               \n",
      "hello    1   2   3   4\n",
      "world    5   6   7   8\n",
      "foo      9  10  11  12\n",
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       two  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     foo\n"
     ]
    }
   ],
   "source": [
    "!cat pydata-book/examples/ex1.csv\n",
    "print()\n",
    "\n",
    "# How to import a CSV file\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('pydata-book/examples/ex1.csv')\n",
    "print(df1) # In this case the contents of the file are already perfect\n",
    "\n",
    "# What if the file had no column names\n",
    "!cat pydata-book/examples/ex2.csv\n",
    "print()\n",
    "df2 = pd.read_csv('pydata-book/examples/ex2.csv', header=None, names=['a', 'b', 'c', 'd', 'message'], index_col='message')\n",
    "print(df2)\n",
    "\n",
    "# What if the file has no delimeter and used something like a space to seperate values\n",
    "!cat pydata-book/examples/ex3.txt\n",
    "print()\n",
    "df3 = pd.read_csv('pydata-book/examples/ex3.txt', index_col=0, sep='\\s+')\n",
    "print(df3)\n",
    "\n",
    "# What if the first, third and fourth rows were not useful\n",
    "!cat pydata-book/examples/ex4.csv\n",
    "df4 = pd.read_csv('pydata-book/examples/ex4.csv', index_col='message', skiprows=[0, 2, 3])\n",
    "print(df4)\n",
    "\n",
    "# If data has missing values represented with a special symbol or word use the arguement na_values so that\n",
    "# np.nan can be put in place of those special symbols in the dataframe\n",
    "df5 = pd.read_csv('pydata-book/examples/ex5.csv', na_values=['NULL', 'NA'])\n",
    "print(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        one       two     three      four key\n",
      "0  0.467976 -0.038649 -0.295344 -1.824726   L\n",
      "1 -0.358893  1.404453  0.704965 -0.200638   B\n",
      "2 -0.501840  0.659254 -0.421691 -0.057688   G\n",
      "3  0.204886  1.074134  1.388361 -0.982404   R\n",
      "4  0.354628 -0.133116  0.283763 -0.837063   Q\n",
      "E    368.0\n",
      "X    364.0\n",
      "L    346.0\n",
      "O    343.0\n",
      "Q    340.0\n",
      "M    338.0\n",
      "J    337.0\n",
      "F    335.0\n",
      "K    334.0\n",
      "H    330.0\n",
      "V    328.0\n",
      "I    327.0\n",
      "U    326.0\n",
      "P    324.0\n",
      "D    320.0\n",
      "A    320.0\n",
      "R    318.0\n",
      "Y    314.0\n",
      "G    308.0\n",
      "S    308.0\n",
      "N    306.0\n",
      "W    305.0\n",
      "T    304.0\n",
      "B    302.0\n",
      "Z    288.0\n",
      "C    286.0\n",
      "4    171.0\n",
      "6    166.0\n",
      "7    164.0\n",
      "8    162.0\n",
      "3    162.0\n",
      "5    157.0\n",
      "2    152.0\n",
      "0    151.0\n",
      "9    150.0\n",
      "1    146.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Reading text files in pieces\n",
    "# What if you only want to read n rows in the data, ignoring the header \n",
    "df6 = pd.read_csv('pydata-book/examples/ex6.csv', nrows=5)\n",
    "print(df6)\n",
    "\n",
    "# You want to read the file in chunks of x rows\n",
    "df6_iter = pd.read_csv('pydata-book/examples/ex6.csv', chunksize=1000) # Returns an iterable\n",
    "totals = pd.Series([], dtype='int64')\n",
    "for chunk in df6_iter:\n",
    "    totals = totals.add(chunk.key.value_counts(), fill_value=0)\n",
    "\n",
    "totals = totals.sort_values(ascending=False)\n",
    "print(totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  something  a   b     c   d message\n",
      "0       one  1   2   3.0   4     NaN\n",
      "1       two  5   6   NaN   8   world\n",
      "2     three  9  10  11.0  12     foo\n",
      " something a b c d message\n",
      "0 one 1 2 3.0 4 NULL\n",
      "1 two 5 6 NULL 8 world\n",
      "2 three 9 10 11.0 12 foo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Writing dataframes to an output (can be a file or the console sys.stdout)\n",
    "df5 = pd.read_csv('pydata-book/examples/ex5.csv', na_values=['NULL', 'NA'])\n",
    "print(df5)\n",
    "\n",
    "# Export using to_csv method\n",
    "df5.to_csv(sys.stdout, na_rep='NULL', sep=' ') # sep specifies seperator and na_rep specifies how to \n",
    "# represent null values in output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Wes', 'cities_lived': ['Akron', 'Nashville', 'New York', 'San Francisco'], 'pet': None, 'siblings': [{'name': 'Scott', 'age': 34, 'hobbies': ['guitars', 'soccer']}, {'name': 'Katie', 'age': 42, 'hobbies': ['diving', 'art']}]}\n",
      "{\"name\": \"Wes\", \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"], \"pet\": null, \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]}, {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]}\n",
      "    name  age\n",
      "0  Scott   34\n",
      "1  Katie   42\n",
      "   a  b  c\n",
      "0  1  2  3\n",
      "1  4  5  6\n",
      "2  7  8  9\n",
      "{\"a\":{\"0\":1,\"1\":4,\"2\":7},\"b\":{\"0\":2,\"1\":5,\"2\":8},\"c\":{\"0\":3,\"1\":6,\"2\":9}}\n"
     ]
    }
   ],
   "source": [
    "# Working with JSON in python\n",
    "import json\n",
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"cities_lived\": [\"Akron\", \"Nashville\", \"New York\", \"San Francisco\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 34, \"hobbies\": [\"guitars\", \"soccer\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 42, \"hobbies\": [\"diving\", \"art\"]}]\n",
    "}\n",
    "\"\"\" # A JSON string\n",
    "\n",
    "# Convert to python obj\n",
    "data = json.loads(obj)\n",
    "print(data)\n",
    "\n",
    "# Convert python obj back to JSON\n",
    "data_json = json.dumps(data)\n",
    "print(data_json)\n",
    "\n",
    "# Create a dataframe from list of JSON objects\n",
    "df = pd.DataFrame(data['siblings'], columns=['name', 'age'])\n",
    "print(df)\n",
    "\n",
    "# You can also convert JSON directly to a dataframe or series using pd.read_json\n",
    "df2 = pd.read_json('pydata-book/examples/example.json')\n",
    "print(df2)\n",
    "\n",
    "# To convert dataframe to JSON use df.to_json\n",
    "df_json = df2.to_json()\n",
    "print(df_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "                      Bank Name             City  ST   CERT  \\\n",
      "0                   Allied Bank         Mulberry  AR     91   \n",
      "1  The Woodbury Banking Company         Woodbury  GA  11297   \n",
      "2        First CornerStone Bank  King of Prussia  PA  35312   \n",
      "3            Trust Company Bank          Memphis  TN   9956   \n",
      "4    North Milwaukee State Bank        Milwaukee  WI  20364   \n",
      "\n",
      "                 Acquiring Institution        Closing Date       Updated Date  \n",
      "0                         Today's Bank  September 23, 2016  November 17, 2016  \n",
      "1                          United Bank     August 19, 2016  November 17, 2016  \n",
      "2  First-Citizens Bank & Trust Company         May 6, 2016  September 6, 2016  \n",
      "3           The Bank of Fayette County      April 29, 2016  September 6, 2016  \n",
      "4  First-Citizens Bank & Trust Company      March 11, 2016      June 16, 2016  \n"
     ]
    }
   ],
   "source": [
    "# Working with HTML\n",
    "tables = pd.read_html('pydata-book/examples/fdic_failed_bank_list.html')\n",
    "print(len(tables))\n",
    "print(tables[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sheet1']\n",
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n",
      "   a   b   c   d message\n",
      "0  1   2   3   4   hello\n",
      "1  5   6   7   8   world\n",
      "2  9  10  11  12     foo\n"
     ]
    }
   ],
   "source": [
    "# Working with Excel Files\n",
    "\n",
    "# Importing the entire file with all of its sheets\n",
    "excel_file = pd.ExcelFile('pydata-book/examples/ex1.xlsx')\n",
    "\n",
    "# Attributes include the names of sheet in the file\n",
    "print(excel_file.sheet_names)\n",
    "\n",
    "# You can then parse a sheet from the file as a DataFrame\n",
    "excel_df = excel_file.parse(sheet_name='Sheet1', index_col=0)\n",
    "print(excel_df)\n",
    "\n",
    "# If you only need a sheet from the excel file as a dataframe you can use read_excel command\n",
    "excel_df = pd.read_excel('pydata-book/examples/ex1.xlsx', sheet_name='Sheet1', index_col=0)\n",
    "print(excel_df)\n",
    "\n",
    "# To convert dataframe to excel use to_excel method\n",
    "excel_df.to_excel('new.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "TST/CLN: Avoid subprocess shell=True\n",
      "    number                                              title  \\\n",
      "0    49033               TST/CLN: Avoid subprocess shell=True   \n",
      "1    49032  REG: fix regression in df.corrwith on tied dat...   \n",
      "2    49031  Suppress false positive pylint findings for 'n...   \n",
      "3    49029  CI: Investigate slow macOS build time for Pyth...   \n",
      "4    49025  pylint: disable invalid-repr-returned in Serie...   \n",
      "5    49024                           PDEP0004: implementation   \n",
      "6    49023  QST: Python pandas 1.3.5 to 1.4.0 breaking cha...   \n",
      "7    49021  BUG: comparing pd.Timedelta with timedelta.max...   \n",
      "8    49018                   pylint: fix misplaced-bare-raise   \n",
      "9    49017                    CLN: tseries/offsets base tests   \n",
      "10   49016  BUG: `MultiIndex.sortlevel` not working correc...   \n",
      "11   49014  API: retain non-nano timedelta64 dtype in Data...   \n",
      "12   49011  differences in Series.map with defaultdict wit...   \n",
      "13   49010             PERF: MultiIndex setops with sort=None   \n",
      "14   49008            ENH: retain reso in Timestamp(dt64_obj)   \n",
      "15   49005  DOC: Fix typos and standardize spelling of \"Gi...   \n",
      "16   49004       CLN/TST: Use fixture instead of setup_method   \n",
      "17   49001     REF: Define ops on Resampler as normal methods   \n",
      "18   49000  CLN/TST: Remove testing ArrowExtensionArray in...   \n",
      "19   48999                           CLN: test_nanops/take.py   \n",
      "20   48998             Copy-on-Write follow-up overview issue   \n",
      "21   48997  Backport PR #48987 on branch 1.5.x (REG: Fix r...   \n",
      "22   48996  BUG: CoW - correctly track references for chai...   \n",
      "23   48995       REGR: to_parquet raising with bytes filename   \n",
      "24   48991                                  RLS: pandas 1.5.1   \n",
      "25   48990  DOC: replace developer meeting with contributo...   \n",
      "26   48988       CI: pydata sphinx theme 0.11 broke doc build   \n",
      "27   48986  ENH: Allow hierarchical sorting on MultiIndex,...   \n",
      "28   48985            DOC: Improve documented types for merge   \n",
      "29   48984  DOC: Update xdist to provide more speed-up opt...   \n",
      "\n",
      "                                               labels state  \n",
      "0   [{'id': 127685, 'node_id': 'MDU6TGFiZWwxMjc2OD...  open  \n",
      "1                                                  []  open  \n",
      "2   [{'id': 106935113, 'node_id': 'MDU6TGFiZWwxMDY...  open  \n",
      "3   [{'id': 48070600, 'node_id': 'MDU6TGFiZWw0ODA3...  open  \n",
      "4   [{'id': 106935113, 'node_id': 'MDU6TGFiZWwxMDY...  open  \n",
      "5   [{'id': 211840, 'node_id': 'MDU6TGFiZWwyMTE4ND...  open  \n",
      "6   [{'id': 32815646, 'node_id': 'MDU6TGFiZWwzMjgx...  open  \n",
      "7   [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "8   [{'id': 106935113, 'node_id': 'MDU6TGFiZWwxMDY...  open  \n",
      "9   [{'id': 127685, 'node_id': 'MDU6TGFiZWwxMjc2OD...  open  \n",
      "10  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "11                                                 []  open  \n",
      "12  [{'id': 2822342, 'node_id': 'MDU6TGFiZWwyODIyM...  open  \n",
      "13  [{'id': 8935311, 'node_id': 'MDU6TGFiZWw4OTM1M...  open  \n",
      "14  [{'id': 3713792788, 'node_id': 'LA_kwDOAA0YD87...  open  \n",
      "15  [{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...  open  \n",
      "16  [{'id': 127685, 'node_id': 'MDU6TGFiZWwxMjc2OD...  open  \n",
      "17  [{'id': 127681, 'node_id': 'MDU6TGFiZWwxMjc2OD...  open  \n",
      "18  [{'id': 127685, 'node_id': 'MDU6TGFiZWwxMjc2OD...  open  \n",
      "19  [{'id': 127685, 'node_id': 'MDU6TGFiZWwxMjc2OD...  open  \n",
      "20  [{'id': 183784729, 'node_id': 'MDU6TGFiZWwxODM...  open  \n",
      "21  [{'id': 127685, 'node_id': 'MDU6TGFiZWwxMjc2OD...  open  \n",
      "22  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n",
      "23  [{'id': 32815646, 'node_id': 'MDU6TGFiZWwzMjgx...  open  \n",
      "24  [{'id': 131473665, 'node_id': 'MDU6TGFiZWwxMzE...  open  \n",
      "25  [{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...  open  \n",
      "26  [{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...  open  \n",
      "27  [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n",
      "28  [{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...  open  \n",
      "29  [{'id': 134699, 'node_id': 'MDU6TGFiZWwxMzQ2OT...  open  \n"
     ]
    }
   ],
   "source": [
    "# Working with web APIs\n",
    "import requests\n",
    "\n",
    "# Get request\n",
    "url = 'https://api.github.com/repos/pandas-dev/pandas/issues'\n",
    "# Make request to URL\n",
    "resp = requests.get(url)\n",
    "resp.raise_for_status() # Raises an error if HTTPError occured\n",
    "print(resp)\n",
    "\n",
    "body = resp.json()\n",
    "print(body[0]['title'])\n",
    "\n",
    "# Create a dataframe from body and choose columns of interest\n",
    "github_df = pd.DataFrame(body, columns=['number', 'title', 'labels', 'state'])\n",
    "print(github_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('datasciencestar': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51c9cea8a4711522a4bf8b45c200e690e948b7adecc3dbdd4ef9333c51e9d22c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
